{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import deque\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import networkx \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('wiki-topcats-reduced.txt', sep=r'\\t', header=None,  names=['Source','Destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>401135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1069112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>12162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>167659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Destination\n",
       "0      52       401135\n",
       "1      52      1069112\n",
       "2      52      1163551\n",
       "3      62        12162\n",
       "4      62       167659"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of Edges__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Edges: 2645247\n"
     ]
    }
   ],
   "source": [
    "num_of_edges = df.shape[0]\n",
    "print('Number of Edges:', num_of_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of Nodes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes: 461193\n"
     ]
    }
   ],
   "source": [
    "nodes = set(df['Source'].values).union(set(df['Destination'].values))\n",
    "num_of_nodes = len(nodes)\n",
    "print('Number of Nodes:', num_of_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Checking to see if our graph is directed?__ <br>\n",
    "\n",
    "we create the graph once for source nodes as the keys and once for destination nodes as our keys. If intersection set between a similar key in two dictionaries is not empty, we have a proof to show our graph is directed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dictionary with source nodes as the key\n",
    "out_Link = df.groupby(['Source'])['Destination'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dictionary with destination nodes as the key\n",
    "in_Link = df.groupby(['Destination'])['Source'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249369\n"
     ]
    }
   ],
   "source": [
    "# checking how many similar keys have non empty intersection sets?\n",
    "intersect_ = {}\n",
    "intersect = 0\n",
    "for item in out_Link.keys():\n",
    "    if item in in_Link.keys():\n",
    "        intersect = set(out_Link[item]).intersection(set(in_Link[item]))\n",
    "        if len(intersect)>0:   \n",
    "            intersect_[item] = set(out_Link[item]).intersection(set(in_Link[item]))\n",
    "print(len(intersect_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We have enough proof to show that our graph is Directed!__<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The average node degree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average node degree: 5\n"
     ]
    }
   ],
   "source": [
    "average_degree = num_of_edges/num_of_nodes\n",
    "print('average node degree:', average_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Checking density of our graph__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph density: 1.2436602635647606e-05\n"
     ]
    }
   ],
   "source": [
    "D = num_of_edges/(num_of_nodes*(num_of_nodes-1))\n",
    "print('graph density:', D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If D is close to 1 it means that graph is dense, so our graph is not dense (close to 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Categories data set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = {}\n",
    "with open('wiki-topcats-categories.txt') as file:\n",
    "    for list_ in file:\n",
    "        if 20000>len(list_.split()[1:])>3500: #we choose only those categories with number of nodes bigger that 3500\n",
    "            categories[list_.split()[0][9:-1]] = list(map(int,list_.split()[1:])) #a dictionary with 'key' as category name and values a list of integers, each integer indicates a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['English_footballers', 'The_Football_League_players', 'Association_football_forwards', 'Association_football_goalkeepers', 'Association_football_midfielders', 'Association_football_defenders', 'Year_of_birth_unknown', 'Harvard_University_alumni', 'Major_League_Baseball_pitchers', 'Members_of_the_United_Kingdom_Parliament_for_English_constituencies', 'Indian_films', 'Year_of_death_missing', 'English_cricketers', 'Rivers_of_Romania', 'Main_Belt_asteroids', 'Asteroids_named_for_people', 'English-language_albums', 'English_television_actors', 'British_films', 'American_films', 'Fellows_of_the_Royal_Society', 'People_from_New_York_City', 'American_Jews', 'American_television_actors', 'American_film_actors', 'Debut_albums', 'Black-and-white_films', 'Year_of_birth_missing', 'Place_of_birth_missing_(living_people)', 'Article_Feedback_Pilot', 'American_military_personnel_of_World_War_II', 'Windows_games'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Getting rid of those nodes in categories that are not in the reduced graph__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want only those nodes that are in the reduced graph.\n",
    "graph_categories = {}\n",
    "for key in categories.keys():\n",
    "    article_set = set(categories.get(key)).intersection(nodes)\n",
    "    graph_categories.update({key:article_set})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_categories_df = pd.DataFrame()\n",
    "graph_categories_df['Categories'] = list(graph_categories.keys())\n",
    "graph_categories_df['Articles'] = list(graph_categories.values())\n",
    "art_len = [len(elem) for elem in list(graph_categories.values())]\n",
    "graph_categories_df['Count'] = art_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# after taking the intersection of each categories' value list with unique nodes in our reduced graph, we again check to \n",
    "# select those categories with higer value length of 3500\n",
    "graph_categories_df = graph_categories_df[graph_categories_df['Count']>3500].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>{622642, 622644, 622647, 622649, 557114, 62266...</td>\n",
       "      <td>7538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>{1671189, 622644, 622647, 622649, 557114, 1245...</td>\n",
       "      <td>7814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Association_football_forwards</td>\n",
       "      <td>{1671189, 884758, 884785, 1671225, 884795, 884...</td>\n",
       "      <td>5097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Association_football_goalkeepers</td>\n",
       "      <td>{737292, 737293, 1671183, 73743, 106515, 10651...</td>\n",
       "      <td>3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>{1671168, 884755, 884774, 622637, 1671214, 167...</td>\n",
       "      <td>5827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>{81920, 1359875, 1359879, 802827, 81936, 10651...</td>\n",
       "      <td>4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harvard_University_alumni</td>\n",
       "      <td>{1638406, 1638409, 1245204, 294956, 1048629, 6...</td>\n",
       "      <td>5549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Major_League_Baseball_pitchers</td>\n",
       "      <td>{1671480, 1278327, 1278328, 328097, 1278406, 3...</td>\n",
       "      <td>5192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Members_of_the_United_Kingdom_Parliament_for_E...</td>\n",
       "      <td>{1048670, 1147049, 1147262, 1147295, 1507751, ...</td>\n",
       "      <td>6491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian_films</td>\n",
       "      <td>{589824, 589825, 589826, 589827, 589828, 58982...</td>\n",
       "      <td>5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year_of_death_missing</td>\n",
       "      <td>{1048576, 1048577, 1048578, 1048579, 1261874, ...</td>\n",
       "      <td>4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rivers_of_Romania</td>\n",
       "      <td>{786432, 786433, 786434, 786435, 786436, 78643...</td>\n",
       "      <td>7729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Main_Belt_asteroids</td>\n",
       "      <td>{1589148, 1589149, 1589152, 1589153, 1589154, ...</td>\n",
       "      <td>11660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>{1589248, 1138689, 1589252, 1138698, 876555, 9...</td>\n",
       "      <td>4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>English-language_albums</td>\n",
       "      <td>{1228800, 1228801, 1597442, 1590777, 1228822, ...</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>British_films</td>\n",
       "      <td>{1056769, 1056770, 1056774, 1245190, 1064970, ...</td>\n",
       "      <td>4422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>American_films</td>\n",
       "      <td>{1245194, 1245195, 1507340, 1638414, 1245201, ...</td>\n",
       "      <td>15159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>People_from_New_York_City</td>\n",
       "      <td>{557059, 294917, 16389, 1277957, 1130509, 6881...</td>\n",
       "      <td>4614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>{1605634, 1376259, 655377, 655392, 1376294, 13...</td>\n",
       "      <td>11531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>{1376259, 655392, 1376294, 1376295, 1277995, 2...</td>\n",
       "      <td>13865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>{1277978, 1048631, 1278015, 1278021, 1278023, ...</td>\n",
       "      <td>7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>{589847, 589848, 589882, 1245243, 1245264, 124...</td>\n",
       "      <td>10759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>{753664, 1048576, 1048578, 1048579, 1048577, 1...</td>\n",
       "      <td>4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>{655361, 1376257, 1376259, 491528, 1572888, 16...</td>\n",
       "      <td>5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>American_military_personnel_of_World_War_II</td>\n",
       "      <td>{385025, 1409026, 1163267, 1056773, 1409032, 2...</td>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Windows_games</td>\n",
       "      <td>{1736708, 1720326, 1507335, 1507337, 1507342, ...</td>\n",
       "      <td>4025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Categories  \\\n",
       "0                                 English_footballers   \n",
       "1                         The_Football_League_players   \n",
       "2                       Association_football_forwards   \n",
       "3                    Association_football_goalkeepers   \n",
       "4                    Association_football_midfielders   \n",
       "5                      Association_football_defenders   \n",
       "6                           Harvard_University_alumni   \n",
       "7                      Major_League_Baseball_pitchers   \n",
       "8   Members_of_the_United_Kingdom_Parliament_for_E...   \n",
       "9                                        Indian_films   \n",
       "10                              Year_of_death_missing   \n",
       "11                                  Rivers_of_Romania   \n",
       "12                                Main_Belt_asteroids   \n",
       "13                         Asteroids_named_for_people   \n",
       "14                            English-language_albums   \n",
       "15                                      British_films   \n",
       "16                                     American_films   \n",
       "17                          People_from_New_York_City   \n",
       "18                         American_television_actors   \n",
       "19                               American_film_actors   \n",
       "20                                       Debut_albums   \n",
       "21                              Black-and-white_films   \n",
       "22                              Year_of_birth_missing   \n",
       "23             Place_of_birth_missing_(living_people)   \n",
       "24        American_military_personnel_of_World_War_II   \n",
       "25                                      Windows_games   \n",
       "\n",
       "                                             Articles  Count  \n",
       "0   {622642, 622644, 622647, 622649, 557114, 62266...   7538  \n",
       "1   {1671189, 622644, 622647, 622649, 557114, 1245...   7814  \n",
       "2   {1671189, 884758, 884785, 1671225, 884795, 884...   5097  \n",
       "3   {737292, 737293, 1671183, 73743, 106515, 10651...   3737  \n",
       "4   {1671168, 884755, 884774, 622637, 1671214, 167...   5827  \n",
       "5   {81920, 1359875, 1359879, 802827, 81936, 10651...   4588  \n",
       "6   {1638406, 1638409, 1245204, 294956, 1048629, 6...   5549  \n",
       "7   {1671480, 1278327, 1278328, 328097, 1278406, 3...   5192  \n",
       "8   {1048670, 1147049, 1147262, 1147295, 1507751, ...   6491  \n",
       "9   {589824, 589825, 589826, 589827, 589828, 58982...   5568  \n",
       "10  {1048576, 1048577, 1048578, 1048579, 1261874, ...   4122  \n",
       "11  {786432, 786433, 786434, 786435, 786436, 78643...   7729  \n",
       "12  {1589148, 1589149, 1589152, 1589153, 1589154, ...  11660  \n",
       "13  {1589248, 1138689, 1589252, 1138698, 876555, 9...   4895  \n",
       "14  {1228800, 1228801, 1597442, 1590777, 1228822, ...   4760  \n",
       "15  {1056769, 1056770, 1056774, 1245190, 1064970, ...   4422  \n",
       "16  {1245194, 1245195, 1507340, 1638414, 1245201, ...  15159  \n",
       "17  {557059, 294917, 16389, 1277957, 1130509, 6881...   4614  \n",
       "18  {1605634, 1376259, 655377, 655392, 1376294, 13...  11531  \n",
       "19  {1376259, 655392, 1376294, 1376295, 1277995, 2...  13865  \n",
       "20  {1277978, 1048631, 1278015, 1278021, 1278023, ...   7561  \n",
       "21  {589847, 589848, 589882, 1245243, 1245264, 124...  10759  \n",
       "22  {753664, 1048576, 1048578, 1048579, 1048577, 1...   4346  \n",
       "23  {655361, 1376257, 1376259, 491528, 1572888, 16...   5532  \n",
       "24  {385025, 1409026, 1163267, 1056773, 1409032, 2...   3720  \n",
       "25  {1736708, 1720326, 1507335, 1507337, 1507342, ...   4025  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_categories_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Doing the same cleaning for the dictionary__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for having in our dictionary only categories with more than 3500 articles\n",
    "for elem in list(graph_categories.keys()):\n",
    "    if elem not in graph_categories_df['Categories'].tolist():\n",
    "        del graph_categories[elem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__all the noeds after cleaning the categories__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139433"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted({x for v in graph_categories.values() for x in v}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the shortest path\n",
    "\n",
    "Given that the distance is the number of hops, and is optimal (shortest path.) We may keep track of visited nodes and current reachable nodes using Python's list/set. Starts from the first node and then keep hopping from the current set of nodes until we reach the target.\n",
    "The point of visited-node list is to prevent visiting the visited nodes, resulting in a loop. And to get shortest distance, it's no use to make a revisit as it always makes the distance of resulting path longer.\n",
    "This is a simple implementation of Breadth-first search. The efficiency partly depends on how to check visited nodes, and how to query adjacent nodes of given node. The Breadth-first search always guarantee to give optimal distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input category\n",
    "C0_name = 'English_footballers'\n",
    "C0 = graph_categories[C0_name][0:999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Shortest Path \n",
    "\n",
    "so i uploaded HM5-draft_Kat.ipynb, i changed only part 1, finally we received undirected graph. i checked it with Adjacency lists as for this check we have only two options Adjacency lists and Adjacency matrix(matrix is even more consuming, so it's the only way).\n",
    "\n",
    "and i also changed formula of computing density of graph, as in Wiki formula with 2 in numerator, so i decided that its right.\n",
    "\n",
    "also i wrote another code for computing average degree of nodes, but we don't need it as for undirected graphs we can use Samin's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def BFS_with_saving_path(graph, start):#this returns a tree for each node \n",
    "    visited = {start} #visited nodes\n",
    "    queue = deque([(start, [])]) #putting the first node in a queue\n",
    "    sav_path = {} #saved path will be a dictionary or a set?\n",
    "    \n",
    "    while queue: #until our queue is filled with something\n",
    "        current, path = queue.popleft() #pop out in FIFO order, get the current node and the path(is only one node here)\n",
    "        try:\n",
    "            for neighbor in graph[current]: #for every neighbor of current node do as follows\n",
    "                if neighbor not in visited: #if neighbor is not visited yet\n",
    "                    queue.append((neighbor, path + [current]))\n",
    "                    visited.add(neighbor)\n",
    "                    sav_path[neighbor] = current\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return sav_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ShortestPath(graph, start, goal, tree):\n",
    "    path = []\n",
    "    if start == goal:\n",
    "        return(len(path))\n",
    "    elif goal not in tree:\n",
    "        return(math.inf)\n",
    "    else:\n",
    "        current = goal\n",
    "        while current != start:\n",
    "            path.append(tree[current])\n",
    "            current = tree[current]\n",
    "        return(len(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_(C0, key):\n",
    "    Ci = graph_categories[key]#to calculate shortest paths for pairs in (C0, Ci)\n",
    "    path_C0_Ci = []\n",
    "    for start in tqdm(C0):#source node in C0\n",
    "        tree = BFS_with_saving_path(out_Link, start)#gives us a tree from start in C0 and all the other nodes in the graph\n",
    "        infinite = 0#to keep the number of paths that do not exist\n",
    "        for end in Ci:#destination node in category Ci\n",
    "            shortest_path_value = ShortestPath(out_Link, start, end, tree)\n",
    "            if shortest_path_value == math.inf:\n",
    "                #path_Ci_Cj_dict['inf'] = [path_Ci_Cj_dict['inf'][0] + 1]\n",
    "                infinite += 1\n",
    "            path_C0_Ci.append(shortest_path_value) # [5,2,4,3]   \n",
    "    path_C0_Ci.append(infinite)\n",
    "    return(path_C0_Ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7538/7538 [1:57:34<00:00,  1.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7538/7538 [2:09:13<00:00,  1.03s/it]\n",
      " 72%|███████████████████████████████████████████████████████                     | 5459/7538 [1:30:20<34:17,  1.01it/s]"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "Ci_to_Cj_sp_values = []\n",
    "for key in graph_categories.keys():\n",
    "    if key != C0_name:\n",
    "        Ci_to_Cj_sp_values = cal_(C0, key) # a list of values each for the shortest paths between nodes in C0 and Ci\n",
    "    #finding the median\n",
    "    ranks.append(tuple((key, np.median(Ci_to_Cj_sp_values))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3737/3737 [1:17:38<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4658.674535274506 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "path_Ci_Cj_dict = {'inf':[0],'val':[]}#a dictionary with two keys, one 'inf' for counting number of infinites, the other, idk?!\n",
    "distances_from_C0 = {'C1':[0,0,0]}#why do we have 3 zeros here?\n",
    "#For category in categories:\n",
    "for start in tqdm(C0):\n",
    "    tree = BFS_with_saving_path(out_Link, start) #here we create a tree. Root is one node in C0\n",
    "    for end in C1:\n",
    "        #print(start)\n",
    "        path = ShortestPath(out_Link,start,end,tree)\n",
    "        #print(start, end, path)\n",
    "        if path == math.inf:\n",
    "            path_Ci_Cj_dict['inf'] = [path_Ci_Cj_dict['inf'][0] + 1]\n",
    "        else:\n",
    "            path_Ci_Cj_dict['val'].append(path) # [5,2,4,3]\n",
    "    \n",
    "    #print('path_Ci_Cj_dict', path_Ci_Cj_dict)\n",
    "    distances_from_C0['C1'] = [distances_from_C0['C1'][0] + path_Ci_Cj_dict['inf'][0], \\\n",
    "                               distances_from_C0['C1'][1] + len(path_Ci_Cj_dict['val']), \\\n",
    "                               distances_from_C0['C1'][2] + sum(path_Ci_Cj_dict['val'])]\n",
    "    path_Ci_Cj_dict = {'inf':[0],'val':[]}\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': [8889460, 10158029, 56407254]}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_from_C0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2 - Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_gr = networkx.DiGraph(out_Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7538"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(C0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an induced graph from input category C0\n",
    "C0 =  list(graph_categories.values())[0]\n",
    "C0_sub = initial_gr.subgraph(C0)\n",
    "in_degree_dict = C0_sub.in_degree()\n",
    "#sort in_degree_dict here, based on the values\n",
    "sorted_ = []\n",
    "sorted_.append = sorted(in_degree_dict.items(), key=lambda x: x[1])#a list of tuples, sorted according to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7538"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([*in_degree_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__second_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for category in tqdm(list(graph_categories.values())[1:]):\n",
    "    empty_ = []# a list of lists. Each item in this list is a category cosists of articles that belong to it\n",
    "    Ci = category #[23,45,..] a list of articles\n",
    "    Ci = Ci.difference(C0) #we should not consider those nodes shared between C0 and Ci so we get the difference. difference is those nodes that belong to Ci and not C0\n",
    "    induced_gr = initial_gr.subgraph(set(C0).union(set(Ci))# we create an induced sub_graph. \n",
    "    \n",
    "    for i, node in enumertae(Ci):\n",
    "        score = 0\n",
    "        if len(induced_gr.in_edges(node)) == 0:\n",
    "            score = 0\n",
    "    \n",
    "        else:\n",
    "            for item in induced_gr.in_edges(node):\n",
    "                if item[0] in Ci:\n",
    "                    score += 1\n",
    "                if item[0] in [*in_degree_dict]:\n",
    "                    score += in_degree_dict[item[0]]\n",
    "                \n",
    "        empty_.append((node, score)) # in_degree_dict is not working for me here\n",
    "    #sort in_degree_dict for all the nodes\n",
    "    sorted_.append(sorted(empty_, key=lambda x: x[1]))  #a list of lists of sorted categories                                \n",
    "                                     \n",
    "    C0 = induced_gr.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
